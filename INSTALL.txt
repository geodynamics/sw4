-----------------------------------------------------------------------
-
-  For SW4 install and build instructions, see the document 
-  "Installing SW4, version 2.0", which is included in doc/SW4-Installation.pdf
-
-----------------------------------------------------------------------


Build instructions for Power9/V100 machines ( Summit, Lassen, Sierra etc)
-----------------------------------------------------------------------------------------------

1. Get Raja(0.11.0)  from github : 
   wget https://github.com/LLNL/RAJA/releases/download/v0.11.0/RAJA-v0.11.0.tar.gz

2. build and install RAJA using the following invocations in the build directory:
   ml cmake cuda gcc/6.4.0 ( Summit only)
   mkdir build  && cd build
   cmake -DCMAKE_INSTALL_PREFIX=../install -DENABLE_CUDA=On -DENABLE_OPENMP=Off ../
   make install

3. Get Umpire(3.0.0) from github:
   wget https://github.com/LLNL/Umpire/releases/download/v3.0.0/umpire-3.0.0.tar.gz

4. build and install Umpire using:
   mkdir build  && cd build
   cmake -DCMAKE_INSTALL_PREFIX=../install -DENABLE_CUDA=On -DENABLE_OPENMP=Off ../
   make install


5. Get Proj 8.1.1 from https://proj.org/download.html:
   wget https://download.osgeo.org/proj/proj-8.1.1.tar.gz

6. build and install Proj using:
   ml sqlite
   mkdir build && cd build
   cmake -DCMAKE_INSTALL_PREFIX=../install  ../
   make install

7. git clone SW4 and checkout the Raja branch
   copy configs/make.raja.<machinename> to make.inc
   Edit make.inc and point RAJA_LOCATION and UMPIRE_HOME to the install locations from Step 2 and 3
   Point PROJ_HOME to the location of the Proj library
   ml fftw
   ml gcc
   ml netlib-lapack/3.8.0 ( Summit only)
   make -j 4
   ** Sometimes parallel make will fail due to a race condition. Redoing make will fix this **
8. To use HDF features, enable HDF5 in the make.inc add paths to HDF5 on your machine
 
   To compile HDF5, download CMake-hdf5-1.10.6.tar.gz from https://www.hdfgroup.org/downloads/hdf5/
   Add MPI=On to the build-unix.sh file so that it looks like this:
	ctest -S HDF5config.cmake,BUILD_GENERATOR=Unix,MPI=On -C Release -V -O hdf5.log
   Edit HDF5options.cmake to add te following ( Works on LLNL machines with lrun) to the
	if (DEFINED MPI) section.
    set (ADD_BUILD_OPTIONS "${ADD_BUILD_OPTIONS} -DMPIEXEC_EXECUTABLE:STRING=lrun")
    set (ADD_BUILD_OPTIONS "${ADD_BUILD_OPTIONS} -DMPIEXEC_NUMPROC_FLAG:STRING=-T")
    set (ADD_BUILD_OPTIONS "${ADD_BUILD_OPTIONS} -DMPIEXEC_MAX_NUMPROCS:STRING=4")
    
    On a compute node run build-unix.sh
    After its done compiling and testing, take tar.gz file from build and install
    Modify the HDF5_HOME dir in make.inc 

9. How to install sqlite if a suitable version is unavailable and use with Proj v8.1.1
   git clone -c feature.manyFiles=true https://github.com/spack/spack.git
   cd spack/bin/
   ./spack install zlib
   spack install sqlite
   ./spack install sqlite
   Copy path to spack sqlite install and use in cmake command below
   cmake -DCMAKE_INSTALL_PREFIX=../install -DCMAKE_PREFIX_PATH=<PATH_TO_SQLITE_INSTALL> ..
   cmake --build .
   cmake --build . --target install

Running SW4 on Summit:
-------------------------------

1. Edit the runsw4.lsf file below and submit using bsub runsw4.lsf.

2. The -n option to jsrun should be 6 times the number of nodes in the #BSUB -nnodes line

3. To run in a interactive allocation ( obtained using : bsub -W 0:30 -nnodes 1 -P GEO130 -Is /bin/tcsh )   
   use the jsrun command with an appropriate -n option


Sample LSF file:
-------------------

#!/bin/bash
#BSUB -P GEO130
#BSUB -W 24:00
#BSUB -nnodes 1200
#BSUB -J SW4
#BSUB -o RunSW4_%J.out
#BSUB -e RunSW4_%J.err
cd /gpfs/alpine/geo130/proj-shared/sw4_raja/10HZ 
module load netlib-lapack/3.8.0
module load cuda
module load xl
module load fftw
module load sqlite
date
jsrun -n 7200 -g1 -c7 -a1 ./sw4 test.in

-----------------------------------------------------------------------

Running SW4 on Lassen:
-----------------------------------------------------------------------

Change the -nnodes, -W , -G and -q options as needed:

bsub -alloc_flags "smt1 cpublink autonumaoff" -nnodes 2048 -W 30:00 -G lcstaff -core_isolation 2 -q pbatch lrun -T4 ./sw4 test.in

To run in an interactive allocation use:

lrun -T4 ./sw4 test.in

---------------------------------------------------------------------
Building using cmake ( Experimental WIP)
---------------------------------------------------------------------
0. git checkout raja. Then in the top level directory: git submodule update --init --recursive
1. module load gcc/8.3.1 , the gcc version of lapack and paralell HDF5
2. proj4 needs to be built by hand and the path passed to cmake. The copy in the tpl sub-directory may be used. see examples in host-config
4  mkdir build && cd build
5  cmake -C ../host-config/<host>.cmake ../
6  make -j 80 ( on a compute node

---------------------------------------------------------------------
Building and running on Crusher
---------------------------------------------------------------------
0. ml  PrgEnv-amd cray-hdf5-parallel fftw cray-python
1. cp make.raja.crusher.RU22.03 to make.inc in config/
2. make -f Makefile.hipcc -j 5
3. see performance/large/run.crusher.scr for run command

---------------------------------------------------------------------
Building Proj6+ on Crusher
---------------------------------------------------------------------

0. wget https://download.osgeo.org/proj/proj-9.0.0.tar.gz
1. ml sqlite libtiff
2. mkdir build && cd build
3. cmake -DCMAKE_INSTALL_PREFIX=../install  ../
4. make install -j 5
